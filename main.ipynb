{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1K19z5oYi5Es9x1C3Ik0kN62Z0wEBbY57",
      "authorship_tag": "ABX9TyPCsHfx/2/fWBI7LnpnlqcA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXKQdDCDzkSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeidhId-z9q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('drive/My Drive/input_titanic/train.csv').fillna(0)\n",
        "test_data = pd.read_csv('drive/My Drive/input_titanic/test.csv').fillna(0)"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKFU2CO26Iwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data[['Sex']] = train_data[['Sex']].replace('male', 1).replace('female', 0)\n",
        "train_data[['Pclass']] = train_data[['Pclass']]\n",
        "train_data[['Age']] = train_data[['Age']] / 100\n",
        "train_data[['Fare']] = train_data[['Fare']] / 100\n",
        "train_data[['Parch']] = train_data[['Parch']] / 10\n",
        "train = train_data[['Pclass', 'Sex', 'Parch', 'Age','Fare']]\n",
        "test = train_data[['Survived']]"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k7FVvfJ9bSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train.to_numpy()\n",
        "x_test = test.to_numpy()\n",
        "\n",
        "# y_train = train.to_numpy()[800:]\n",
        "# y_test = test.to_numpy()[800:]"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuwQEyQZAo7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data[['Sex']] = test_data[['Sex']].replace('male', 1).replace('female', 0)\n",
        "test_data[['Pclass']] = test_data[['Pclass']]\n",
        "test_data[['Age']] = test_data[['Age']] / 100\n",
        "test_data[['Fare']] = test_data[['Fare']] / 100\n",
        "test_data[['Parch']] = test_data[['Parch']] / 10\n",
        "\n",
        "export_test_data = test_data[['Pclass', 'Sex', 'Parch', 'Age','Fare']].to_numpy()\n",
        "export_ids = test_data[['PassengerId']].to_numpy()"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjdlsaXqBEPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2e81f2bc-4e46-4bd8-c9c2-3b535560ebec"
      },
      "source": [
        "print(export_test_data[:10])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.       1.       0.       0.345    0.078292]\n",
            " [3.       0.       0.       0.47     0.07    ]\n",
            " [2.       1.       0.       0.62     0.096875]\n",
            " [3.       1.       0.       0.27     0.086625]\n",
            " [3.       0.       0.1      0.22     0.122875]\n",
            " [3.       1.       0.       0.14     0.09225 ]\n",
            " [3.       0.       0.       0.3      0.076292]\n",
            " [2.       1.       0.1      0.26     0.29    ]\n",
            " [3.       0.       0.       0.18     0.072292]\n",
            " [3.       1.       0.       0.21     0.2415  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEEwf98d-hDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "fe92e6b1-ce0f-4f17-a80f-76e18e396a97"
      },
      "source": [
        "with np.printoptions(threshold=np.inf):\n",
        "    print(x_train[:15])"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.   1.   0.22]\n",
            " [1.   0.   0.38]\n",
            " [3.   0.   0.26]\n",
            " [1.   0.   0.35]\n",
            " [3.   1.   0.35]\n",
            " [3.   1.   0.  ]\n",
            " [1.   1.   0.54]\n",
            " [3.   1.   0.02]\n",
            " [3.   0.   0.27]\n",
            " [2.   0.   0.14]\n",
            " [3.   0.   0.04]\n",
            " [1.   0.   0.58]\n",
            " [3.   1.   0.2 ]\n",
            " [3.   1.   0.39]\n",
            " [3.   0.   0.14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXQCULW1-SBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fca0b76f-783b-473a-953f-c3e1a208afd4"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(800, 5)\n",
            "(91, 5)\n",
            "(800, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0x9T_2NETec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "17fc8000-1992-48a1-aa52-f5c15b684d3b"
      },
      "source": [
        "g = sns.catplot(x=\"Parch\", y=\"Survived\", data=train_data,\n",
        "                height=6, kind=\"bar\", palette=\"muted\")\n",
        "g.despine(left=True)\n",
        "g.set_ylabels(\"survival probability\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f6b744901d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAGoCAYAAAATsnHAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYSUlEQVR4nO3dbbBlVX3n8e+PBoJBBA2JbdGMdCJGkThCUYAjE0E0gg8w5dOAMUYl6clEIikSu0hGCOLMi3RGHHXQcKMoMipBxUnP2EpMgg/R4aFbFATEtEBCt1x5UAwgBsH/vDi7yaHpvvdA333OOvd+P1W3ztn7rLvOfxdF/+5ee+21U1VIktSanSZdgCRJ22JASZKaZEBJkppkQEmSmmRASZKatPOkC3gMnHYoSYtLtrXTMyhJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSk3oLqCTnJbktyTe383mSvCfJxiRXJzm4r1okSdOnzzOoDwPHzPH5scD+3c8q4P091iJJmjK9PbCwqr6UZL85mhwPfKSqCrgsyV5JnlJVt/ZVkzQtVq9ezezsLMuXL2fNmjWTLkeaiEleg9oHuGVoe1O37xGSrEqyPsn6mZmZsRQnTdLs7CybN29mdnZ20qVIEzMVj3yvqhlgSzL5yHdJWgImeQa1Gdh3aHtFt0+SpIkG1Frg9d1svsOBH3r9SZK0RW9DfEk+DhwJ7J1kE/AnwC4AVfXnwDrgJcBG4EfAG/uqRZI0ffqcxXfiPJ8X8Oa+vl+SNN1cSUKS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1KReAyrJMUluSLIxyWnb+PzfJLk0yVVJrk7ykj7rkSRNj94CKsky4BzgWOAA4MQkB2zV7G3ARVV1EHAC8L6+6pEkTZc+z6AOBTZW1Y1VdT9wIXD8Vm0KeEL3fk/guz3WI0maIn0G1D7ALUPbm7p9w84EXpdkE7AO+L1tdZRkVZL1SdbPzMz0UaskqTE7T/j7TwQ+XFXvTPJc4IIkB1bVT4cbVdUMsCWZatxFSpLGr88zqM3AvkPbK7p9w04CLgKoqv8H7Abs3WNNkqQp0WdAXQnsn2Rlkl0ZTIJYu1WbfwKOBkjyTAYBdXuPNUmSpkRvAVVVDwAnA5cA1zOYrXdtkrOSHNc1+wPgt5N8A/g48IaqcghPktTvNaiqWsdg8sPwvjOG3l8HPK/PGiRJ08mVJCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNmjegkvzKOAqRJGnYKGdQ70tyRZLfTbJn7xVJkgTsPF+Dqvr3SfYH3gRsSHIF8KGq+nzv1WlBrV69mtnZWZYvX86aNWsmXY4kzWnegAKoqn9I8jZgPfAe4KAkAf64qi7us0AtnNnZWTZv3jzpMiRpJKNcg3p2kncB1wMvAF5eVc/s3r+r5/okSUvUKGdQ7wU+wOBs6b4tO6vqu91ZlSRJC26USRKfrqoLhsMpySkAVXVBb5VJkpa0UQLq9dvY94YFrkOSpIfZ7hBfkhOB1wIrk6wd+mgP4Pt9FyZJWtrmugb1VeBWYG/gnUP77wau7rMoSZK2G1BV9Y/APwLPHV85kiQNzDXE9/dVdUSSu4Ea/gioqnpC79VJkpasuc6gjuhe9xhfOZIkDcx1BvWkuX6xqpwooYlz+SZp8ZprksQGBkN72cZnBfxiLxVJj4LLN0mL11xDfCvHWYgkScO2e6Nukmd0rwdv62eUzpMck+SGJBuTnLadNq9Jcl2Sa5N87LEdhiRpsZlriO9UYBUPvwdqi2KwWOx2JVkGnAO8CNgEXJlkbVVdN9Rmf+CPgOdV1Q+S/MKjrF+StEjNNcS3qns96jH2fSiwsapuBEhyIXA8cN1Qm98GzqmqH3Tfddtj/C5Jmggn6vRn3tXMk+wG/C5wBIMzpy8Df15VP57nV/cBbhna3gQctlWbp3ff8RVgGXBmVX1uGzWsYnA2x7nnnsuqVavmK1sam8tOOWXB+/zx7bc/9LqQ/R/+7ncvWF8acKJOf0Z53MZHGCxv9N5u+7XABcCrF+j79weOBFYAX0ryK1V113CjqpoBZrZsLsD3SpIaN0pAHVhVBwxtX5rkuu22/lebgX2Htld0+4ZtAi6vqp8ANyX5NoPAunKE/iVJi9goj9v4WpLDt2wkOYzBo9/ncyWwf5KVSXYFTgDWbtXmfzM4eyLJ3gyG/G4coW9J0iI310oS1zAYTtsF+GqSf+q2nwp8a76Oq+qBJCcDlzC4vnReVV2b5CxgfVWt7T77te6M7EHgrVV1544elCRp+s01xPeyHe28qtYB67bad8bQ+2Iwnf3UHf0uSdLiMt/jNh7S3aO0W+8VSZLECNegkhyX5B+Am4AvAjcDn+25LknSEjfKJIl3AIcD3+7W5zsauKzXqiRJS94oAfWTbuLCTkl2qqpLgUN6rkuStMSNch/UXUkez2AFiY8muQ24t9+yJElL3ShnUMcD9wG/D3wO+A7w8j6LkiRp3jOoqro3yXIGi79+H7jEe5UkSX0bZRbfbwFXAK8AXgVcluRNfRcmSVraRrkG9VbgoC1nTUl+DvgqcF6fhUmSlrZRrkHdyWA18y3u7vZJktSbudbi27L80Ebg8iR/xWAtvuOBq8dQmyRpCZtriG+P7vU73c8Wf9VfOZIkDcy1Ft/bh7e7e6Goqnv6LkoD3/7vb1jQ/n7yg+899LqQfT/9Dz+8YH1J0hajzOI7MMlVwLXAtUk2JHlW/6VJkpayUSZJzACnVtVTq+qpwB8Af9FvWZKkpW6UgNq9W38PgKr6ArB7bxVJksRo90HdmOR04IJu+3X4WHZJUs9GOYN6E/DzwMXAp4C9u32SJPVmzjOoJMuAi6vqqDHVI0kSMM8ZVFU9CPw0yZ5jqkeSJGC0a1D3ANck+TxDz4Gqqrf0VpUkackbJaAu7n4kSRqbUZ4HdX6SXYFnMFiL74aqur/3yiRJS9q8AZXkJcC5DNbjC7AyyX+qqs/2XZwkaekaZYjvbOCoqtoIkOSXgM8ABpQkqTej3Ad195Zw6tzIw58PJUnSghvlDGp9knXARQyuQb0auDLJKwCqygkUkqQFN0pA7QZ8D3h+t3078Djg5QwCy4CSJC24UWbxvXEchUiSNGyUa1CSJI3dKEN80oJZ/YVTF7S/O+67/aHXhe57zZFnL2h/kh4dz6AkSU3a7hlUkjn/HK0q/7yUJPVmriG+PcZWhSRJW9luQFXV28dZiCRJw0ZZi2834CTgWQzuiQKgqnyqriSpN6NMkrgAWA68GPgisAKXOpIk9WyUgHpaVZ0O3FtV5wMvBQ7rtyxJ0lI3SkD9pHu9K8mBwJ7AL/RXkiRJo92oO5PkicDpwFrg8d17SZJ6M0pAfaiqHmRw/ekXe65HkiRgtCG+m5LMJDk6SXqvSJIkRguoZwB/A7wZuDnJ/0xyRL9lSZKWunkDqqp+VFUXVdUrgOcAT2Aw3CdJUm9GWiw2yfOTvA/YwOBm3df0WpUkackbZSWJm4GrGDzy/a1VdW/fRUmSNMosvmdX1T/3Xol693OPW/awV0lq2VyP21hdVWuA/5aktv68qt7Sa2VacG851PurJU2Puc6gru9e14+jEEmShs31uI3/0729pqq+NqZ6JEkCRpvF984k1yd5R7cWnyRJvRvlPqijgKOA24Fzk1yT5G29VyZJWtJGug+qqmar6j3A7wBfB87otSpJ0pI3b0AleWaSM5NcA7wX+CqDhxZKktSbUe6DOg+4EHhxVX2353okSQLmCagky4CbqurdY6pHkiRgniG+7jlQ+ybZdUz1SJIEjDbEdxPwlSRrgYfW4auqs3urSpK05I0SUN/pfnYC9ui3HEmSBuYNqKp6+zgKkSRp2CiP27gU2NZisS/opSJJkhhtiO8Ph97vBrwSeKCfciRJGhhliG/DVru+kuSKnuqRJAkYbSWJJw397J3kxcCeo3Se5JgkNyTZmOS0Odq9MkklOeRR1C5JWsRGGeLbwOAaVBgM7d0EnDTfL3U3+Z4DvAjYBFyZZG1VXbdVuz2AU4DLH13pkqTFbJQhvpWPse9DgY1VdSNAkguB44Hrtmr3DuBPgbc+xu+RJC1Cowzxvbo7yyHJ25JcnOTgEfreB7hlaHtTt2+474OBfavqM/PUsCrJ+iTrZ2ZmRvhqSdK0G2WI7/Sq+kSSI4AXAn8GvB84bEe+OMlOwNnAG+ZrW1UzwJZkesSUdy1du+6168NeJS0eowTUg93rS4GZqvpMkv86wu9tBvYd2l7R7dtiD+BA4AtJAJYDa5McV1XrR+hf4um//kuTLkFST0Z5YOHmJOcC/xFYl+RnRvy9K4H9k6zsFps9AVi75cOq+mFV7V1V+1XVfsBlgOEkSQJGC5rXAJcweB7UXcCTGGFCQ1U9AJzc/e71wEVVdW2Ss5IctwM1S5KWgFFm8f0IuHho+1bg1lE6r6p1wLqt9m3zcfFVdeQofUqSloZRzqAkSRq7USZJLEmrV69mdnaW5cuXs2bNmkmXI0lLjgG1HbOzs2zevHn+hpKkXjjEJ0lqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJatKiWCz2tWd8YcH7vOPO+wCYvfO+Be3/Y2cduWB9SdJi5hmUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJBpQkqUkGlCSpSQaUJKlJi2I18z4s222vh71KksbLgNqOJz7r1yddgiQtaQ7xSZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkppkQEmSmmRASZKaZEBJkprUa0AlOSbJDUk2JjltG5+fmuS6JFcn+dskT+2zHknS9OgtoJIsA84BjgUOAE5McsBWza4CDqmqZwOfBNb0VY8kabr0eQZ1KLCxqm6sqvuBC4HjhxtU1aVV9aNu8zJgRY/1SJKmSJ8BtQ9wy9D2pm7f9pwEfLbHeiRJU2TnSRcAkOR1wCHA87fz+SpgFcC5557LqlWrxlidpMXiHSe9eMH7/P73HuheNy9o/6d/8JIF62ta9RlQm4F9h7ZXdPseJskLgf8CPL+q/mVbHVXVDDCzZXOB65Sa88RddnnYq7QU9RlQVwL7J1nJIJhOAF473CDJQcC5wDFVdVuPtUhT5Y0rV066BGniersGVVUPACcDlwDXAxdV1bVJzkpyXNfsz4DHA59I8vUka/uqR5I0XXq9BlVV64B1W+07Y+j9C/v8fknS9HIlCUlSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSk3oNqCTHJLkhycYkp23j859J8pfd55cn2a/PeiRJ06O3gEqyDDgHOBY4ADgxyQFbNTsJ+EFVPQ14F/CnfdUjSZoufZ5BHQpsrKobq+p+4ELg+K3aHA+c373/JHB0kvRYkyRpSqSq+uk4eRVwTFX9Vrf9G8BhVXXyUJtvdm02ddvf6drcsVVfq4BV3eZuwI97KfqR9gbumLfVdPGYpsdiPK7FeEywOI9rnMd0R1Uds/XOncf05TukqmaAmXF/b5L1VXXIuL+3Tx7T9FiMx7UYjwkW53G1cEx9DvFtBvYd2l7R7dtmmyQ7A3sCd/ZYkyRpSvQZUFcC+ydZmWRX4ARg7VZt1gK/2b1/FfB31deYoyRpqvQ2xFdVDyQ5GbgEWAacV1XXJjkLWF9Va4EPAhck2Qh8n0GItWTsw4pj4DFNj8V4XIvxmGBxHtfEj6m3SRKSJO0IV5KQJDXJgJIkNcmA2ob5lmiaRknOS3Jbd+/ZopBk3ySXJrkuybVJTpl0TTsqyW5Jrkjyje6Y3j7pmhZSkmVJrkryfyddy0JIcnOSa5J8Pcn6SdezEJLsleSTSb6V5Pokz51YLV6DerhuiaZvAy8CNjGYjXhiVV030cJ2UJJfBe4BPlJVB066noWQ5CnAU6rqa0n2ADYA/2Ga/1t1K6nsXlX3JNkF+HvglKq6bMKlLYgkpwKHAE+oqpdNup4dleRm4JCtFxeYZknOB75cVR/oZmD/bFXdNYlaPIN6pFGWaJo6VfUlBjMlF42qurWqvta9vxu4HthnslXtmBq4p9vcpftZFH9FJlkBvBT4wKRr0bYl2RP4VQYzrKmq+ycVTmBAbcs+wC1D25uY8n/0loJuJfyDgMsnW8mO64bBvg7cBny+qqb+mDr/A1gN/HTShSygAv46yYZuSbZptxK4HfhQNxT7gSS7T6oYA0pTL8njgU8Bv19V/zzpenZUVT1YVc9hsPrKoUmmfkg2ycuA26pqw6RrWWBHVNXBDJ7a8OZuKH2a7QwcDLy/qg4C7gUmdh3egHqkUZZoUiO66zSfAj5aVRdPup6F1A2tXAo8YhHNKfQ84Ljums2FwAuS/K/JlrTjqmpz93ob8GkGlwim2SZg09BZ+ycZBNZEGFCPNMoSTWpAN6Hgg8D1VXX2pOtZCEl+Psle3fvHMZis863JVrXjquqPqmpFVe3H4P+pv6uq1024rB2SZPducg7dMNivAVM9S7aqZoFbkvxyt+toYGKTjqZiNfNx2t4STRMua4cl+ThwJLB3kk3An1TVBydb1Q57HvAbwDXdNRuAP66qdROsaUc9BTi/m026E3BRVS2KKdmL0JOBT3ePsNsZ+FhVfW6yJS2I3wM+2v2BfiPwxkkV4jRzSVKTHOKTJDXJgJIkNcmAkiQ1yYCSJDXJgJIkNcmAksYgyYPditffTPKJJD+7g/3tt5hWppe2xYCSxuO+qnpOt5L8/cDvjPJLSbxXUUuWASWN35eBpyV5eZLLu0U5/ybJkwGSnJnkgiRfAS5I8uQkn+6eEfWNJP+u62dZkr/onhv1193KE9KiYUBJY9SdER0LXMPgWU+Hd4tyXshgpe8tDgBeWFUnAu8BvlhV/5bBumhbVjbZHzinqp4F3AW8cjxHIY2HwwfSeDxuaDmmLzNYQ/CXgb/sHry4K3DTUPu1VXVf9/4FwOthsNI58MMkTwRuqqotfW4A9uv3EKTxMqCk8bive4TGQ5K8Fzi7qtYmORI4c+jje0fo81+G3j8IOMSnRcUhPmly9uRfH+Xym3O0+1vgP8NDDzPcs+/CpBYYUNLknAl8IskG4I452p0CHJXkGgZDeQeMoTZp4lzNXJLUJM+gJElNMqAkSU0yoCRJTTKgJElNMqAkSU0yoCRJTTKgJElN+v9eHMKh7ycl3gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbUcQJRb2-Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot( x = 'Survived', data = train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHLxs5nC3Xvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot( x = 'Survived', hue = 'Sex', data = train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJy-gEhC41hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot( x = 'Survived', hue = 'Pclass', data = train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJMVYdXfRCx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('val_accuracy')>0.85 and logs.get('accuracy')>0.8 and logs.get('loss') < 0.4):\n",
        "            print(\"\\nReached 40% loss so cancelling training!\")\n",
        "            self.model.stop_training = True\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcTb3ZIT5bF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "733318c9-101e-424b-9d3f-c107304c7a2a"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(250, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(120, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, x_test, epochs=150)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7430\n",
            "Epoch 2/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7778\n",
            "Epoch 3/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7789\n",
            "Epoch 4/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7789\n",
            "Epoch 5/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7834\n",
            "Epoch 6/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7901\n",
            "Epoch 7/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7890\n",
            "Epoch 8/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7767\n",
            "Epoch 9/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7924\n",
            "Epoch 10/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7935\n",
            "Epoch 11/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7912\n",
            "Epoch 12/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7991\n",
            "Epoch 13/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7879\n",
            "Epoch 14/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.8002\n",
            "Epoch 15/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7946\n",
            "Epoch 16/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8013\n",
            "Epoch 17/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7980\n",
            "Epoch 18/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8036\n",
            "Epoch 19/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8081\n",
            "Epoch 20/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7980\n",
            "Epoch 21/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8047\n",
            "Epoch 22/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8058\n",
            "Epoch 23/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8092\n",
            "Epoch 24/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7957\n",
            "Epoch 25/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7969\n",
            "Epoch 26/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.8103\n",
            "Epoch 27/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8148\n",
            "Epoch 28/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8103\n",
            "Epoch 29/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8137\n",
            "Epoch 30/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8092\n",
            "Epoch 31/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8013\n",
            "Epoch 32/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8148\n",
            "Epoch 33/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8182\n",
            "Epoch 34/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8092\n",
            "Epoch 35/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8114\n",
            "Epoch 36/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8070\n",
            "Epoch 37/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8081\n",
            "Epoch 38/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8058\n",
            "Epoch 39/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8047\n",
            "Epoch 40/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8047\n",
            "Epoch 41/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8114\n",
            "Epoch 42/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8047\n",
            "Epoch 43/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8092\n",
            "Epoch 44/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8092\n",
            "Epoch 45/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8148\n",
            "Epoch 46/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8159\n",
            "Epoch 47/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8137\n",
            "Epoch 48/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8103\n",
            "Epoch 49/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8114\n",
            "Epoch 50/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8159\n",
            "Epoch 51/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8137\n",
            "Epoch 52/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8126\n",
            "Epoch 53/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8193\n",
            "Epoch 54/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8137\n",
            "Epoch 55/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8159\n",
            "Epoch 56/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8137\n",
            "Epoch 57/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8103\n",
            "Epoch 58/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8148\n",
            "Epoch 59/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8215\n",
            "Epoch 60/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8249\n",
            "Epoch 61/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8137\n",
            "Epoch 62/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8092\n",
            "Epoch 63/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8249\n",
            "Epoch 64/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8272\n",
            "Epoch 65/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8171\n",
            "Epoch 66/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8238\n",
            "Epoch 67/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8193\n",
            "Epoch 68/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8249\n",
            "Epoch 69/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8294\n",
            "Epoch 70/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8272\n",
            "Epoch 71/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8316\n",
            "Epoch 72/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8215\n",
            "Epoch 73/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8339\n",
            "Epoch 74/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8215\n",
            "Epoch 75/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8316\n",
            "Epoch 76/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8283\n",
            "Epoch 77/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8339\n",
            "Epoch 78/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8305\n",
            "Epoch 79/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8272\n",
            "Epoch 80/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8305\n",
            "Epoch 81/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8204\n",
            "Epoch 82/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8215\n",
            "Epoch 83/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8260\n",
            "Epoch 84/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8249\n",
            "Epoch 85/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8305\n",
            "Epoch 86/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8272\n",
            "Epoch 87/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8361\n",
            "Epoch 88/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8260\n",
            "Epoch 89/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8227\n",
            "Epoch 90/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8238\n",
            "Epoch 91/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8316\n",
            "Epoch 92/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8361\n",
            "Epoch 93/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8283\n",
            "Epoch 94/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8171\n",
            "Epoch 95/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8462\n",
            "Epoch 96/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8227\n",
            "Epoch 97/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8339\n",
            "Epoch 98/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8339\n",
            "Epoch 99/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8283\n",
            "Epoch 100/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8395\n",
            "Epoch 101/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8339\n",
            "Epoch 102/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8260\n",
            "Epoch 103/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8249\n",
            "Epoch 104/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8418\n",
            "Epoch 105/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8361\n",
            "Epoch 106/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8328\n",
            "Epoch 107/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8373\n",
            "Epoch 108/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8384\n",
            "Epoch 109/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8406\n",
            "Epoch 110/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3839 - accuracy: 0.8328\n",
            "Epoch 111/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8350\n",
            "Epoch 112/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8429\n",
            "Epoch 113/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8418\n",
            "Epoch 114/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8406\n",
            "Epoch 115/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8272\n",
            "Epoch 116/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8350\n",
            "Epoch 117/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8462\n",
            "Epoch 118/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8350\n",
            "Epoch 119/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8418\n",
            "Epoch 120/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8395\n",
            "Epoch 121/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8373\n",
            "Epoch 122/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8328\n",
            "Epoch 123/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8395\n",
            "Epoch 124/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8418\n",
            "Epoch 125/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8418\n",
            "Epoch 126/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8339\n",
            "Epoch 127/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8373\n",
            "Epoch 128/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8451\n",
            "Epoch 129/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8294\n",
            "Epoch 130/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8429\n",
            "Epoch 131/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8429\n",
            "Epoch 132/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8440\n",
            "Epoch 133/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8418\n",
            "Epoch 134/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8418\n",
            "Epoch 135/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8429\n",
            "Epoch 136/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8485\n",
            "Epoch 137/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8429\n",
            "Epoch 138/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8485\n",
            "Epoch 139/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8440\n",
            "Epoch 140/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8429\n",
            "Epoch 141/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8384\n",
            "Epoch 142/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8418\n",
            "Epoch 143/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8373\n",
            "Epoch 144/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8361\n",
            "Epoch 145/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8451\n",
            "Epoch 146/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8418\n",
            "Epoch 147/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8373\n",
            "Epoch 148/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8496\n",
            "Epoch 149/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8440\n",
            "Epoch 150/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6af0f03320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZd4kz9SIJJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9856f576-0ab6-4f7e-aeee-ee884dc305cb"
      },
      "source": [
        "model.evaluate(y_train, y_test)\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3492985963821411, 0.8351648449897766]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxqzxaBPAneI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = tf.argmax(model.predict(export_test_data),1).numpy()"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UA87ooPKT8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d11dc431-8d27-47a8-e139-74a7f36f24a8"
      },
      "source": [
        "result = np.array(result, dtype=np.int)\n",
        "result = result.reshape(418, 1)\n",
        "print(export_ids.shape, result.shape)\n",
        "structuredArr = np.concatenate((export_ids, result), axis=1)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(418, 1) (418, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc9iG1VpN0gJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9dfd737e-f5d4-4664-9de8-0e11561637c0"
      },
      "source": [
        "print(result[:10])"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGOzBpVCMIjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('struct_array1.csv', structuredArr, delimiter=',', fmt=['%i' , '%i'], header='PassengerId,Survived', comments='')"
      ],
      "execution_count": 216,
      "outputs": []
    }
  ]
}